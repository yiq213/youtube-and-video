{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dazbo's YouTube and Video Demos\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook forms the first part of a walkthrough series.\n",
    "\n",
    "The overall series covers:\n",
    "\n",
    "1. Starting with an idea. Here, the goal is to work with vidoes, which could be on YouTube. We want to be able to download videos, extract audio, transcribe, translate, and potentially summarise the content.\n",
    "1. Experimenting on this idea, using a Jupyter notebook, with Python.\n",
    "1. Trying a few libraries and a couple of classical AI models. \n",
    "1. Building a solution that makes use of Google Gemini multiomodal GenAI.\n",
    "1. Turning the notebook into a web application, using Streamlit.\n",
    "1. Packaging the application as a container.\n",
    "1. Finally, hosting the application on Google Cloud's serverless Cloud Run service.\n",
    "\n",
    "The code and notebooks are intended to be supplemented by these walkthroughs:\n",
    "\n",
    "1. [Downloading YouTube Videos, Extracting Audio, and Generating Transcripts with Python and Jupyter Notebooks](https://medium.com/python-in-plain-english/downloading-youtube-videos-extracting-audio-and-generating-transcripts-with-python-and-jupyter-c3068f82bbe0)\n",
    "1. [YouTube Video Downloader with Generative AI: Run Anywhere, Transcribe and Translate](https://python.plainenglish.io/youtube-video-downloader-with-generative-ai-and-python-run-anywhere-transcribe-and-translate-dec2e593dd58)\n",
    "1. [Building and Running an AI YouTube and Video Processing as a Python Streamlit Web Application, on Serverless Google Cloud Run](https://medium.com/google-cloud/running-ai-youtube-and-video-processing-as-a-python-streamlit-web-application-and-hosting-on-748aae8e54b4)\n",
    "\n",
    "Additionally, you will find supporting READMEs and scripts in my [GitHub repo](https://github.com/derailed-dash/youtube-and-video).\n",
    "\n",
    "## This Notebook\n",
    "\n",
    "Examples of how to work with YouTube videos using Python. Here I'll demonstrate:\n",
    "\n",
    "- How to [download videos and extract audio](#downloading-videos-and-extracting-audio)\n",
    "- How to [transcribe audio to text using a speech-to-text API](#extracting-audio-using-python-speech-recognition)\n",
    "- How to [extract existing transcripts and translate](#extract-existing-transcripts-from-videos)\n",
    "\n",
    "**To run this notebook, first execute the cells in the [Setup](#Setup) section, as described below.** Then you can experiment with any of the subsequent cells.\n",
    "\n",
    "A few useful notes:\n",
    "\n",
    "- The source for this notebook source lives in my GitHub repo, <a href=\"https://github.com/derailed-dash/youtube-and-video\" target=\"_blank\">Youtube-and-Video</a>.\n",
    "- Check out further guidance - including tips on how to run the notebook, in the project's `README.md`.\n",
    "- For example, you could...\n",
    "  - Run the notebook locally, in your own Jupyter environment.\n",
    "  - Run the notebook in a cloud-based Jupyter environment, with no setup required on your part! For example, with **Google Colab**: <br><br><a href=\"https://colab.research.google.com/github/derailed-dash/youtube-and-video/blob/main/src/notebooks/youtube-demos.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Google Colab\"/></a><br><br>It looks like this:<br><br><img src=\"static/images/collab-view.png\" width=\"640px\"></img>\n",
    "- For more ways to run Jupyter Notebooks, check out [my guide](https://medium.com/python-in-plain-english/five-ways-to-run-jupyter-labs-and-notebooks-23209f71e5c0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "First, let's install any dependent packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: dazbo-commons in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (0.1.5)\n",
      "Requirement already satisfied: pytubefix in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (9.2.0)\n",
      "Requirement already satisfied: moviepy in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: yt_dlp in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (2025.6.9)\n",
      "Requirement already satisfied: colorama>=0.4.6 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from dazbo-commons) (0.4.6)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from moviepy) (5.2.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from moviepy) (2.3.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: pillow<12.0,>=9.2.0 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from moviepy) (11.2.1)\n",
      "Requirement already satisfied: tqdm in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from proglog<=1.0.0->moviepy) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --no-cache-dir python-dotenv dazbo-commons pytubefix moviepy yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import display\n",
    "from IPython.core.display import Markdown\n",
    "\n",
    "import logging\n",
    "import re\n",
    "import io\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import dazbo_commons as dc\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (6.29.5)\n",
      "Requirement already satisfied: appnope in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (9.3.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (27.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Colab requires an older version of Ipykernel\n",
    "if not \"google.colab\" in sys.modules:\n",
    "    pass\n",
    "    %pip install --upgrade --no-cache-dir ipykernel\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging\n",
    "\n",
    "Now we'll setup logging. Here I'm using coloured logging from my [dazbo-commons](https://pypi.org/project/dazbo-commons/) package. Feel free to change the logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m19:22:03.003:dazbo-yt-demos - INF: Logger initialised.\u001b[39m\n",
      "\u001b[34m19:22:03.004:dazbo-yt-demos - DBG: DEBUG level logging enabled.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "APP_NAME=\"dazbo-yt-demos\"\n",
    "logger = dc.retrieve_console_logger(APP_NAME)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.info(\"Logger initialised.\")\n",
    "logger.debug(\"DEBUG level logging enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations\n",
    "\n",
    "Here we initialise some file path locations, e.g. an output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m19:22:03.013:dazbo-yt-demos - DBG: script_name: dazbo-yt-demos\u001b[39m\n",
      "\u001b[34m19:22:03.015:dazbo-yt-demos - DBG: script_dir: /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos\u001b[39m\n",
      "\u001b[34m19:22:03.016:dazbo-yt-demos - DBG: input_dir: /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/input\u001b[39m\n",
      "\u001b[34m19:22:03.016:dazbo-yt-demos - DBG: output_dir: /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/output\u001b[39m\n",
      "\u001b[34m19:22:03.017:dazbo-yt-demos - DBG: input_file: /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/input/input.txt\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "locations = dc.get_locations(APP_NAME)\n",
    "for attribute, value in vars(locations).items():\n",
    "    logger.debug(f\"{attribute}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_filename(filename):\n",
    "    \"\"\" Create a clean filename by removing unallowed characters. \"\"\"\n",
    "    pattern = r'[^a-zA-Z0-9._\\s-]'\n",
    "    return  re.sub(pattern, '_', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Additional Packages You May Need\n",
    "\n",
    "**Bear in mind that `nodejs` is required by the `pytubefix` library, to prevent this appliction being detected as a bot.**\n",
    "\n",
    "You can run the cell below, but it may not work on your environment. So you might need to install packages manually, e.g.\n",
    "\n",
    "<table>\n",
    "  <col style=\"width:10%\">\n",
    "  <col style=\"width:45%\">\n",
    "  <col style=\"width:45%\"> <!-- Adjust as needed or remove for auto-sizing -->\n",
    "  <tr>\n",
    "    <th>Package</th>\n",
    "    <th>Purpose</th>\n",
    "    <th>Install Command</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://ffmpeg.org/\">ffmpeg</a></td>\n",
    "    <td>A useful utility for video and audio format conversion. Many Python libraries use it. It will not generally be used by this notebook, but if you run into errors requiring ffmpeg, you will want to run this section.</td>\n",
    "    <td>Linux: <code>sudo apt install ffmpeg</code><br>Windows: <code>winget install ffmpeg</code></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://xiph.org/flac/download.html\">FLAC</a></td>\n",
    "    <td>The Python <code>speech_recognition</code> library uses the FLAC utility to convert audio files into a format that can be processed for speech recognition.</td>\n",
    "    <td>Linux: <code>sudo apt install flac</code><br>Windows: Download the latest</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>nodejs</td>\n",
    "    <td>The pytubefix library can automatically create YouTube PO tokens, but this relies on nodejs being installed.</td>\n",
    "    <td>Linux: <code>sudo apt install nodejs</code><br>Windows: <code>winget install node.js</code></td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m19:22:03.038:dazbo-yt-demos - DBG: Checking if ffmpeg is installed\u001b[39m\n",
      "\u001b[34m19:22:03.285:dazbo-yt-demos - DBG: ffmpeg version: ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "configuration: --prefix=/usr/local/Cellar/ffmpeg/7.1.1_3 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "libavutil      59. 39.100 / 59. 39.100\n",
      "libavcodec     61. 19.101 / 61. 19.101\n",
      "libavformat    61.  7.100 / 61.  7.100\n",
      "libavdevice    61.  3.100 / 61.  3.100\n",
      "libavfilter    10.  4.100 / 10.  4.100\n",
      "libswscale      8.  3.100 /  8.  3.100\n",
      "libswresample   5.  3.100 /  5.  3.100\n",
      "libpostproc    58.  3.100 / 58.  3.100\u001b[39m\n",
      "\u001b[34m19:22:03.287:dazbo-yt-demos - DBG: ffmpeg is already installed.\u001b[39m\n",
      "\u001b[34m19:22:03.287:dazbo-yt-demos - DBG: Checking if flac is installed\u001b[39m\n",
      "\u001b[34m19:22:03.301:dazbo-yt-demos - DBG: flac version: flac 1.5.0\u001b[39m\n",
      "\u001b[34m19:22:03.302:dazbo-yt-demos - DBG: flac is already installed.\u001b[39m\n",
      "\u001b[34m19:22:03.304:dazbo-yt-demos - DBG: Checking if node is installed\u001b[39m\n",
      "\u001b[34m19:22:03.443:dazbo-yt-demos - DBG: node version: v24.2.0\u001b[39m\n",
      "\u001b[34m19:22:03.445:dazbo-yt-demos - DBG: node is already installed.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\"Run a shell command and print its output in real-time.\"\"\"\n",
    "    process = subprocess.Popen(\n",
    "        command, \n",
    "        shell=True, \n",
    "        stdout=subprocess.PIPE, \n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    \n",
    "    # Read and print the output line by line\n",
    "    if process.stdout is not None:\n",
    "        for line in iter(process.stdout.readline, b''):\n",
    "            logger.info(line.decode().strip())\n",
    "        process.stdout.close()\n",
    "        \n",
    "    process.wait()\n",
    "    \n",
    "def install_software(appname: str):\n",
    "    os_name = platform.system()\n",
    "    logger.info(f\"Installing {appname} on {os_name}...\")\n",
    "    \n",
    "    # Mapping operating systems to their respective installation commands\n",
    "    command_map = {\n",
    "        \"Windows\": f\"winget install {appname} --silent --no-upgrade\",\n",
    "        \"Linux\": f\"apt -qq -y install {appname}\",\n",
    "        \"Darwin\": f\"brew install {appname}\"\n",
    "    }\n",
    "    command = command_map.get(os_name)\n",
    "    if command:\n",
    "        run_command(command)\n",
    "        logger.info(f\"Done.\")\n",
    "    else:\n",
    "        logger.error(f\"Unsupported operating system: {os_name}\")\n",
    "\n",
    "def check_installed(app_exec: str) -> bool:    \n",
    "    appname, *arg = app_exec.split()\n",
    "    arg = \" \".join(arg)\n",
    "    logger.debug(f\"Checking if {appname} is installed\")\n",
    "    \n",
    "    try:\n",
    "        output = subprocess.check_output([appname, arg], stderr=subprocess.STDOUT)\n",
    "        logger.debug(f\"{appname} version: {output.decode().strip()}\")\n",
    "        logger.debug(f\"{appname} is already installed.\")\n",
    "        return True\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        logger.debug(f\"{appname} is not installed or absent from path.\")\n",
    "        \n",
    "    return False\n",
    "\n",
    "apps = [ (\"ffmpeg\", \"ffmpeg -version\"),\n",
    "         (\"flac\", \"flac --version\"),\n",
    "         (\"nodejs\" , \"node --version\"),]\n",
    "          \n",
    "for app_install, app_exec in apps:\n",
    "    if not check_installed(app_exec):\n",
    "        install_software(app_install)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll check `ffmpeg` has been installed.\n",
    "\n",
    "On Windows, this may not have been added to your path. If so, you can check your default install location using `winget --info`, and then add it to your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m19:22:03.455:dazbo-yt-demos - INF: Note that installed applications may not be immediately available after first installing.\n",
      "It may be necessary to relaunch the notebook environment.\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "configuration: --prefix=/usr/local/Cellar/ffmpeg/7.1.1_3 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "libavutil      59. 39.100 / 59. 39.100\n",
      "libavcodec     61. 19.101 / 61. 19.101\n",
      "libavformat    61.  7.100 / 61.  7.100\n",
      "libavdevice    61.  3.100 / 61.  3.100\n",
      "libavfilter    10.  4.100 / 10.  4.100\n",
      "libswscale      8.  3.100 /  8.  3.100\n",
      "libswresample   5.  3.100 /  5.  3.100\n",
      "libpostproc    58.  3.100 / 58.  3.100\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Note that installed applications may not be immediately available after first installing.\\n\" \\\n",
    "            \"It may be necessary to relaunch the notebook environment.\")\n",
    "\n",
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Videos to Work With\n",
    "\n",
    "We start by defining a list of videos to test our application with, along with a function that takes a full YouTube URL and returns just the id portion.\n",
    "\n",
    "I’ve used these videos because…\n",
    "\n",
    "- The first is the fantastic [Burning Bridges](https://www.youtube.com/watch?v=udRAIF6MOm8) by Sigrid. The video has no embedded transcript.\n",
    "- The second is the beautiful song [I Believe](https://www.youtube.com/watch?v=CiTn4j7gVvY) by Melissa Hollick. It’s one of my favourite songs of all time. When I get a migraine, I turn off the lights, and listen to this to feel better! And for those who enjoy gaming, this song is the end titles to the amazing Wolfenstein: New Order game. This video has an embedded transcript.\n",
    "- Then we have a short [Jim Carey speech](https://www.youtube.com/watch?v=nLgHNu2N3JU), which gives us dialog without music or other ambient noise. It has an embedded transcript.\n",
    "- And finally, a [Ukrainian song](https://www.youtube.com/watch?v=d4N82wPpdg8) from Eurovision 2024, by Jerry Heil and Alyona Alyona. This gives us an opportunity to test translation. It also has an embedded transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videos to download\n",
    "urls = [\n",
    "    \"https://www.youtube.com/watch?v=ZbXErZeW-Zo&t=1148s\",  # sunscreen review\n",
    "#     \"https://www.youtube.com/watch?v=CiTn4j7gVvY\",  # Melissa Hollick - I Believe (English)\n",
    "#     \"https://www.youtube.com/watch?v=nLgHNu2N3JU\",  # Jim Carey - Motivational speech (English)\n",
    "#     \"https://www.youtube.com/watch?v=d4N82wPpdg8\",  # Jerry Heil & Alyona Alyona - Teresa & Maria (Ukrainian)\n",
    "#     \"https://www.youtube.com/shorts/41iWg91yFv0\",   # Rick Astley short\n",
    " ]\n",
    "\n",
    "def get_video_id(url: str) -> str:\n",
    "    \"\"\" Return the video ID, which is the part after 'v=' \"\"\"\n",
    "    pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Videos and Extracting Audio\n",
    "\n",
    "Here I'll demonstrate a few different Python libraries for working with YouTube videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 - With PyTubeFix\n",
    "\n",
    "Here I'll use the [pytubefix](https://github.com/JuanBindez/pytubefix) library to download YouTube videos, and then to download mp3 audio-only streams as files.\n",
    "\n",
    "This library is a community-maintained fork of `pytube`. It was created to provide quick fixes for issues that the official pytube library faced, particularly when YouTube's updates break `pytube`.\n",
    "\n",
    "Pros:\n",
    "\n",
    "- The library is very easy to use.\n",
    "- We can work with video, audio, channels, playlists, and even search and filter.\n",
    "- It is [well documented](https://pytubefix.readthedocs.io/en/latest/).\n",
    "- It can be used from the command line, with its simple CLI.\n",
    "- It is VERY FAST!\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Does not offer some of the more sophisticated capabilities that are offered by `yt_dlp`.\n",
    "- It does not appear to set mp3 headers correctly. The mp3s are actually encoded as mp4a. I don't think this is a problem, but it's worth bearing in mind!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m08:25:24.724:dazbo-yt-demos - INF: Downloads progress: 1/1\u001b[39m\n",
      "\u001b[32m08:25:32.564:dazbo-yt-demos - INF: Getting: I Tested The Top 35 Asian Sunscreens... Asian SPF Showdown!\u001b[39m\n",
      "\u001b[32m08:25:36.108:dazbo-yt-demos - INF: Downloading video I Tested The Top 35 Asian Sunscreens... Asian SPF Showdown_.mp4 ...\u001b[39m\n",
      "\u001b[31m08:25:36.177:dazbo-yt-demos - ERR: Error processing URL 'https://www.youtube.com/watch?v=ZbXErZeW-Zo&t=1148s'.\u001b[39m\n",
      "\u001b[31m08:25:36.178:dazbo-yt-demos - ERR: The cause was: HTTP Error 403: Forbidden\u001b[39m\n",
      "\u001b[32m08:25:36.179:dazbo-yt-demos - INF: Downloads finished. See files in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/output/pytubefix.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "\n",
    "output_locn = f\"{locations.output_dir}/pytubefix\"\n",
    "\n",
    "def process_yt_videos():\n",
    "    for i, url in enumerate(urls):\n",
    "        logger.info(f\"Downloads progress: {i+1}/{len(urls)}\")\n",
    "\n",
    "        try:\n",
    "            # YouTube now requires the PO token to be passed in the requet\n",
    "            # The library will automatically generate a PO token, \n",
    "            # but nodejs must be installed to do so.\n",
    "            yt = YouTube(url, on_progress_callback=on_progress, client=\"WEB\")\n",
    "            logger.info(f\"Getting: {yt.title}\")\n",
    "            video_stream = yt.streams.get_highest_resolution()\n",
    "            if not video_stream:\n",
    "                raise Exception(\"Stream not available.\")\n",
    "            \n",
    "            # YouTube resource titles may contain special characters which \n",
    "            # can't be used when saving the file. So we need to clean the filename.\n",
    "            cleaned = clean_filename(yt.title)\n",
    "            \n",
    "            video_output = f\"{output_locn}/{cleaned}.mp4\"\n",
    "            logger.info(f\"Downloading video {cleaned}.mp4 ...\")\n",
    "            video_stream.download(output_path=output_locn, filename=f\"{cleaned}.mp4\")\n",
    "        \n",
    "            logger.info(f\"Creating audio...\")\n",
    "            audio_stream = yt.streams.get_audio_only()\n",
    "            audio_stream.download(output_path=output_locn, filename=f\"{cleaned}.mp3\")\n",
    "            \n",
    "            logger.info(\"Done\")\n",
    "            \n",
    "        except Exception as e:        \n",
    "            logger.error(f\"Error processing URL '{url}'.\")\n",
    "            logger.error(f\"The cause was: {e}\") \n",
    "            \n",
    "    logger.info(f\"Downloads finished. See files in {output_locn}.\")\n",
    "    \n",
    "process_yt_videos()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 - PyTubeFix and MoviePy\n",
    "\n",
    "Here I'm doing the same as before, but I'm extracting the audio using the Python [MoviePy](https://github.com/Zulko/moviepy) library. This is a powerful video and audio editing library. \n",
    "\n",
    "Pros:\n",
    "\n",
    "- We can extract audio as mp3 with correct headers.\n",
    "- It is [well documented](https://zulko.github.io/moviepy/).\n",
    "- It is powerful.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- It is slower to extract the audio than using `pytubefix` alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m19:22:29.175:dazbo-yt-demos - INF: Downloads progress: 1/1\u001b[39m\n",
      "\u001b[32m19:22:31.719:dazbo-yt-demos - INF: Getting: I Tested The Top 35 Asian Sunscreens... Asian SPF Showdown!\u001b[39m\n",
      "\u001b[32m19:22:33.705:dazbo-yt-demos - INF: Downloading video I Tested The Top 35 Asian Sunscreens... Asian SPF Showdown_.mp4 ...\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ↳ |████████████████████████████████████████████| 100.0%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m19:22:45.021:dazbo-yt-demos - INF: Creating audio...\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/output/pytubefix_with_moviepy/I Tested The Top 35 Asian Sunscreens... Asian SPF Showdown_.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m19:23:19.642:dazbo-yt-demos - INF: Done\u001b[39m                       \n",
      "\u001b[32m19:23:19.643:dazbo-yt-demos - INF: Downloads finished. See files in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/output/pytubefix_with_moviepy.\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "from moviepy import VideoFileClip\n",
    "\n",
    "output_locn = f\"{locations.output_dir}/pytubefix_with_moviepy\"\n",
    "\n",
    "def process_yt_videos():\n",
    "    for i, url in enumerate(urls):\n",
    "        logger.info(f\"Downloads progress: {i+1}/{len(urls)}\")\n",
    "\n",
    "        try:\n",
    "            yt = YouTube(url, on_progress_callback=on_progress, client=\"WEB\")\n",
    "            logger.info(f\"Getting: {yt.title}\")\n",
    "            video_stream = yt.streams.get_highest_resolution()\n",
    "            if not video_stream:\n",
    "                raise Exception(\"Stream not available.\")\n",
    "            \n",
    "            # YouTube resource titles may contain special characters which \n",
    "            # can't be used when saving the file. So we need to clean the filename.\n",
    "            cleaned = clean_filename(yt.title)\n",
    "\n",
    "            video_output = f\"{output_locn}/{cleaned}.mp4\"\n",
    "            logger.info(f\"Downloading video {cleaned}.mp4 ...\")\n",
    "            video_stream.download(output_path=output_locn, filename=f\"{cleaned}.mp4\")\n",
    "        \n",
    "            logger.info(f\"Creating audio...\")\n",
    "            video_clip = VideoFileClip(video_output) # purely to give us access to methods\n",
    "            assert video_clip.audio is not None\n",
    "            video_clip.audio.write_audiofile(f\"{output_locn}/{cleaned}.mp3\")\n",
    "            video_clip.close()\n",
    "            \n",
    "            logger.info(\"Done\")\n",
    "            \n",
    "        except Exception as e:        \n",
    "            logger.error(f\"Error processing URL '{url}'.\")\n",
    "            logger.debug(f\"The cause was: {e}\") \n",
    "            \n",
    "    logger.info(f\"Downloads finished. See files in {output_locn}.\")\n",
    "    \n",
    "process_yt_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3 - With YT_DLP\n",
    "\n",
    "I wanted to try the other popular YouTube package: [yt-dlp](https://pypi.org/project/yt-dlp/). The [repo](https://github.com/yt-dlp/yt-dlp) is a fork of the now unmaintained `youtube-dl`. \n",
    "\n",
    "Pros:\n",
    "\n",
    "- It is very powerful, with far more options and features than `pytubefix`.\n",
    "- It can be installed as a standalone command-line executable, or as a pip-installable Python package.\n",
    "- Sets mp3 headers properly!\n",
    "- It has some powerful and network proxy settings. This can be useful if, for example, you are trying to download videos that are geo-restricted.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- It is more complicated to use.\n",
    "- The documentation is complex and somewhat hard to understand. And there's no real Python-specific documentation.\n",
    "- It depends on having ffmpeg installed for some use cases.\n",
    "- It is significantly slower that `pytubefix` for performing video download and audio extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m19:23:19.654:dazbo-yt-demos - INF: Downloads progress: 1/1\u001b[39m\n",
      "\u001b[32m19:23:19.765:dazbo-yt-demos - INF: Downloading video...\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=ZbXErZeW-Zo&t=1148s\n",
      "[youtube] ZbXErZeW-Zo: Downloading webpage\n",
      "[youtube] ZbXErZeW-Zo: Downloading tv client config\n",
      "[youtube] ZbXErZeW-Zo: Downloading tv player API JSON\n",
      "[youtube] ZbXErZeW-Zo: Downloading ios player API JSON\n",
      "[youtube] ZbXErZeW-Zo: Downloading m3u8 information\n",
      "[info] ZbXErZeW-Zo: Downloading 1 format(s): 18\n",
      "[download] /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/output/yt_dlp/I Tested The Top 35 Asian Sunscreens... Asian SPF Showdown!.mp4 has already been downloaded\n",
      "[download] 100% of  172.58MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m19:23:23.809:dazbo-yt-demos - INF: Extracting and saving audio as MP3...\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=ZbXErZeW-Zo&t=1148s\n",
      "[youtube] ZbXErZeW-Zo: Downloading webpage\n",
      "[youtube] ZbXErZeW-Zo: Downloading tv client config\n",
      "[youtube] ZbXErZeW-Zo: Downloading tv player API JSON\n",
      "[youtube] ZbXErZeW-Zo: Downloading ios player API JSON\n",
      "[youtube] ZbXErZeW-Zo: Downloading m3u8 information\n",
      "[info] ZbXErZeW-Zo: Downloading 1 format(s): 251-8\n",
      "[download] Destination: /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/output/yt_dlp/I Tested The Top 35 Asian Sunscreens... Asian SPF Showdown!.webm\n",
      "[download] 100% of   45.25MiB in 00:00:03 at 13.80MiB/s    \n",
      "[ExtractAudio] Destination: /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/output/yt_dlp/I Tested The Top 35 Asian Sunscreens... Asian SPF Showdown!.mp3\n",
      "Deleting original file /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/output/yt_dlp/I Tested The Top 35 Asian Sunscreens... Asian SPF Showdown!.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m19:24:17.642:dazbo-yt-demos - INF: Downloads finished. Check out files at /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/output/yt_dlp.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "output_locn = f\"{locations.output_dir}/yt_dlp\"\n",
    "\n",
    "def process_yt_videos():\n",
    "    for i, url in enumerate(urls):\n",
    "        logger.info(f\"Downloads progress: {i+1}/{len(urls)}\")\n",
    "\n",
    "        try:\n",
    "            # Options for downloading the video\n",
    "            video_opts = {\n",
    "                'format': 'best',  # Download the best quality video\n",
    "                'outtmpl': f'{output_locn}/%(title)s.%(ext)s',  # Save video in output directory\n",
    "            }\n",
    "            \n",
    "            # Download the video\n",
    "            with yt_dlp.YoutubeDL(video_opts) as ydl:\n",
    "                logger.info(\"Downloading video...\")\n",
    "                ydl.download([url])\n",
    "            \n",
    "            # Options for extracting audio and saving as MP3\n",
    "            audio_opts = {\n",
    "                'format': 'bestaudio',  # Download the best quality audio\n",
    "                'outtmpl': f'{output_locn}/%(title)s.%(ext)s',  # Save audio in output directory\n",
    "                'postprocessors': [{\n",
    "                    'key': 'FFmpegExtractAudio',\n",
    "                    'preferredcodec': 'mp3',\n",
    "                }],\n",
    "            }\n",
    "            \n",
    "            # Download and extract audio\n",
    "            with yt_dlp.YoutubeDL(audio_opts) as ydl:\n",
    "                logger.info(\"Extracting and saving audio as MP3...\")\n",
    "                ydl.download([url])\n",
    "            \n",
    "        except Exception as e:        \n",
    "            logger.error(f\"Error processing URL '{url}'.\")\n",
    "            logger.debug(f\"The cause was: {e}\") \n",
    "            \n",
    "    logger.info(f\"Downloads finished. Check out files at {output_locn}.\")\n",
    "    \n",
    "process_yt_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "If you:\n",
    "\n",
    "- Want to just download the videos and/or audio in the simplest and fastest way possible, then go with [Option 1](#option-1---with-pytubefix).\n",
    "- Want to download the videos and/or audio and then carry out some sort of manipulation or conversion of the media, go with [Option 2](#option-2---pytubefix-and-moviepy).\n",
    "- If you want out-of-the-box proxy configuration, e.g. to bypass geo-restrictions, then go with [Option 3](#option-3---with-yt_dlp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing Audio to Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Audio Using Python Speech Recognition\n",
    "\n",
    "The Python `speech_recognition` package has a number of built in `Recognizer` implementations. Here I'm using the [Google Web Speech API](https://wicg.github.io/speech-api/) `Recognizer`, which has its default API key hard coded into the Python `speech_recognition` library. It is free, but has some limitations. For example, it only allows a max of 60s segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (0.25.1)\n",
      "Requirement already satisfied: SpeechRecognition in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (3.14.3)\n",
      "Requirement already satisfied: ffmpeg-python in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from SpeechRecognition) (4.14.0)\n",
      "Requirement already satisfied: future in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from ffmpeg-python) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --no-cache-dir pydub SpeechRecognition ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m19:25:21.873:dazbo-yt-demos - INF: Converting /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/src/notebooks/dazbo-yt-demos/output/yt_dlp/I Tested The Top 35 Asian Sunscreens... Asian SPF Showdown!.mp3...\u001b[39m\n",
      "\u001b[34m19:25:48.000:dazbo-yt-demos - DBG: Chunk 0 extracted.\u001b[39m\n",
      "\u001b[34m19:26:04.972:dazbo-yt-demos - DBG: Chunk 1 extracted.\u001b[39m\n",
      "\u001b[34m19:26:21.730:dazbo-yt-demos - DBG: Chunk 2 extracted.\u001b[39m\n",
      "\u001b[34m19:26:40.974:dazbo-yt-demos - DBG: Chunk 3 extracted.\u001b[39m\n",
      "\u001b[34m19:26:57.365:dazbo-yt-demos - DBG: Chunk 4 extracted.\u001b[39m\n",
      "\u001b[34m19:27:16.002:dazbo-yt-demos - DBG: Chunk 5 extracted.\u001b[39m\n",
      "\u001b[34m19:27:37.806:dazbo-yt-demos - DBG: Chunk 6 extracted.\u001b[39m\n",
      "\u001b[34m19:27:59.420:dazbo-yt-demos - DBG: Chunk 7 extracted.\u001b[39m\n",
      "\u001b[34m19:28:16.761:dazbo-yt-demos - DBG: Chunk 8 extracted.\u001b[39m\n",
      "\u001b[34m19:28:33.828:dazbo-yt-demos - DBG: Chunk 9 extracted.\u001b[39m\n",
      "\u001b[34m19:28:49.487:dazbo-yt-demos - DBG: Chunk 10 extracted.\u001b[39m\n",
      "\u001b[34m19:29:06.858:dazbo-yt-demos - DBG: Chunk 11 extracted.\u001b[39m\n",
      "\u001b[34m19:29:27.169:dazbo-yt-demos - DBG: Chunk 12 extracted.\u001b[39m\n",
      "\u001b[34m19:29:43.461:dazbo-yt-demos - DBG: Chunk 13 extracted.\u001b[39m\n",
      "\u001b[34m19:30:06.860:dazbo-yt-demos - DBG: Chunk 14 extracted.\u001b[39m\n",
      "\u001b[34m19:30:22.463:dazbo-yt-demos - DBG: Chunk 15 extracted.\u001b[39m\n",
      "\u001b[34m19:30:44.492:dazbo-yt-demos - DBG: Chunk 16 extracted.\u001b[39m\n",
      "\u001b[34m19:31:06.073:dazbo-yt-demos - DBG: Chunk 17 extracted.\u001b[39m\n",
      "\u001b[34m19:31:28.936:dazbo-yt-demos - DBG: Chunk 18 extracted.\u001b[39m\n",
      "\u001b[34m19:31:44.465:dazbo-yt-demos - DBG: Chunk 19 extracted.\u001b[39m\n",
      "\u001b[34m19:32:02.398:dazbo-yt-demos - DBG: Chunk 20 extracted.\u001b[39m\n",
      "\u001b[34m19:32:19.932:dazbo-yt-demos - DBG: Chunk 21 extracted.\u001b[39m\n",
      "\u001b[34m19:32:38.140:dazbo-yt-demos - DBG: Chunk 22 extracted.\u001b[39m\n",
      "\u001b[34m19:32:59.478:dazbo-yt-demos - DBG: Chunk 23 extracted.\u001b[39m\n",
      "\u001b[34m19:33:17.050:dazbo-yt-demos - DBG: Chunk 24 extracted.\u001b[39m\n",
      "\u001b[34m19:33:36.833:dazbo-yt-demos - DBG: Chunk 25 extracted.\u001b[39m\n",
      "\u001b[34m19:33:57.279:dazbo-yt-demos - DBG: Chunk 26 extracted.\u001b[39m\n",
      "\u001b[34m19:34:18.273:dazbo-yt-demos - DBG: Chunk 27 extracted.\u001b[39m\n",
      "\u001b[34m19:34:38.104:dazbo-yt-demos - DBG: Chunk 28 extracted.\u001b[39m\n",
      "\u001b[34m19:35:01.893:dazbo-yt-demos - DBG: Chunk 29 extracted.\u001b[39m\n",
      "\u001b[34m19:35:19.717:dazbo-yt-demos - DBG: Chunk 30 extracted.\u001b[39m\n",
      "\u001b[34m19:35:38.906:dazbo-yt-demos - DBG: Chunk 31 extracted.\u001b[39m\n",
      "\u001b[34m19:35:55.170:dazbo-yt-demos - DBG: Chunk 32 extracted.\u001b[39m\n",
      "\u001b[34m19:36:11.894:dazbo-yt-demos - DBG: Chunk 33 extracted.\u001b[39m\n",
      "\u001b[34m19:36:28.604:dazbo-yt-demos - DBG: Chunk 34 extracted.\u001b[39m\n",
      "\u001b[34m19:36:47.556:dazbo-yt-demos - DBG: Chunk 35 extracted.\u001b[39m\n",
      "\u001b[34m19:37:10.617:dazbo-yt-demos - DBG: Chunk 36 extracted.\u001b[39m\n",
      "\u001b[34m19:37:30.040:dazbo-yt-demos - DBG: Chunk 37 extracted.\u001b[39m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     51\u001b[39m         logger.error(\u001b[33m\"\u001b[39m\u001b[33mUnexpected error.\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mDone\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtranscribe_audio\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m recogniser = sr.Recognizer()        \n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mp3_file \u001b[38;5;129;01min\u001b[39;00m Path(output_locn).glob(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m*.mp3\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43mtranscribe_audio_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecogniser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmp3_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mtranscribe_audio_file\u001b[39m\u001b[34m(recogniser, mp3_file, language)\u001b[39m\n\u001b[32m     34\u001b[39m     audio_data = recogniser.record(source)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     extracted = \u001b[43mrecogniser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mChunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m extracted.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m     transcription_extracts[index] = extracted\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:255\u001b[39m, in \u001b[36mrecognize_legacy\u001b[39m\u001b[34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[39m\n\u001b[32m    250\u001b[39m request_builder = create_request_builder(\n\u001b[32m    251\u001b[39m     endpoint=endpoint, key=key, language=language, filter_level=pfilter\n\u001b[32m    252\u001b[39m )\n\u001b[32m    253\u001b[39m request = request_builder.build(audio_data)\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m response_text = \u001b[43mobtain_transcription\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moperation_timeout\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m output_parser = OutputParser(\n\u001b[32m    260\u001b[39m     show_all=show_all, with_confidence=with_confidence\n\u001b[32m    261\u001b[39m )\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_parser.parse(response_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:222\u001b[39m, in \u001b[36mobtain_transcription\u001b[39m\u001b[34m(request, timeout)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m URLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\n\u001b[32m    220\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrecognition connection failed: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(e.reason)\n\u001b[32m    221\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:473\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:595\u001b[39m, in \u001b[36mHTTPResponse._read_chunked\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    593\u001b[39m value = []\n\u001b[32m    594\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m (chunk_left := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    596\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt <= chunk_left:\n\u001b[32m    597\u001b[39m             value.append(\u001b[38;5;28mself\u001b[39m._safe_read(amt))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:579\u001b[39m, in \u001b[36mHTTPResponse._get_chunk_left\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    577\u001b[39m     \u001b[38;5;28mself\u001b[39m._safe_read(\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     chunk_left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m    581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:539\u001b[39m, in \u001b[36mHTTPResponse._read_next_chunk_size\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    538\u001b[39m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    541\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mchunk size\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:708\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    710\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def divide_chunks(sound, segment_size_secs=60):\n",
    "    \"\"\" Split audio file into 60s chunks \"\"\"\n",
    "    \n",
    "    segment_size_ms = segment_size_secs*1000\n",
    "    for start_idx in range(0, len(sound), segment_size_ms):\n",
    "        # Yield a chunk of audio data from start_idx to start_idx + segment_size_ms\n",
    "        yield sound[start_idx:start_idx + segment_size_ms]\n",
    "\n",
    "def transcribe_audio():\n",
    "    \"\"\" Use Speech Recognition API with Google Web Speech API\n",
    "    to convert audio dialog to text \"\"\"\n",
    "    recogniser = sr.Recognizer()        \n",
    "    for mp3_file in Path(output_locn).glob(f'*.mp3'):\n",
    "        transcribe_audio_file(recogniser, mp3_file)\n",
    "\n",
    "def transcribe_audio_file(recogniser, mp3_file, language=\"en-US\"):\n",
    "    logger.info(f\"Converting {mp3_file}...\")\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(mp3_file)\n",
    "        # If AudioSegment is not working - e.g. due to broken mp3 headers - we\n",
    "        # can use ffmpeg as a workaround. However, it's a lot slower.\n",
    "        # ffmpeg.input(mp3_file).output(wav_file).run() # Convert with ffmpeg\n",
    "        # logger.info(f\"Successfully converted {mp3_file} to {wav_file}.\")\n",
    "        # audio = AudioSegment.from_wav(wav_file) # Read the audio\n",
    "\n",
    "        segments = list(divide_chunks(audio, segment_size_secs=60)) # split the wav into 60s segments     \n",
    "        transcription_extracts = {}\n",
    "        for index, chunk in enumerate(segments):\n",
    "            with io.BytesIO() as wav_io:\n",
    "                chunk.export(wav_io, format='wav')\n",
    "                wav_io.seek(0)  # Move to the start of the BytesIO object before reading from it\n",
    "                        \n",
    "                with sr.AudioFile(wav_io) as source:\n",
    "                    audio_data = recogniser.record(source)\n",
    "\n",
    "                try:\n",
    "                    extracted = recogniser.recognize_google(audio_data, language=language)\n",
    "                    logger.debug(f\"Chunk {index} extracted.\")\n",
    "                    transcription_extracts[index] = extracted\n",
    "                except sr.UnknownValueError:\n",
    "                        # Log the unknown value error and continue\n",
    "                    logger.warning(f\"Chunk {index}: Could not understand the audio. Maybe it was empty.\")\n",
    "            \n",
    "        logger.info(\"Extract:\")\n",
    "        for idx, extract in transcription_extracts.items():\n",
    "            logger.info(f\"{idx}: {extract}\")\n",
    "\n",
    "    except ffmpeg.Error as e:\n",
    "        logger.error(f\"FFmpeg failed to convert {mp3_file}: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(\"Unexpected error.\", exc_info=True)\n",
    "            \n",
    "transcribe_audio()\n",
    "logger.info(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "It's a bit flakey!  Sometimes it runs, but sometimes the API returns errors and fails to run.\n",
    "\n",
    "When the API does run...\n",
    "\n",
    "- It fails to transcribe the Ukrainian song. Not too surprising, since this API does not detect language automatically, and defaults to recognising English.\n",
    "- It does an amazing job with the Jim Carey speech.\n",
    "- It is partially successful when transcribing songs.\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "It's not great!  It's pretty good if there's no background sound or ambient noise.  But it's pretty poor when working with songs. And it seems unreliable.\n",
    "\n",
    "### Transcribing Ukrainian\n",
    "\n",
    "Let's try and transcribe from the Ukrainian song:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_ua():\n",
    "    recogniser = sr.Recognizer()\n",
    "    for mp3_file in Path(output_locn).glob(f'alyona*.mp3'):\n",
    "        transcribe_audio_file(recogniser, mp3_file, language=\"uk-UA\")\n",
    "        \n",
    "transcribe_ua()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Partial success.  But overall... Not great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Existing Transcripts from Videos\n",
    "\n",
    "Now I'm going to use the [youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api) to extract existing transcripts from YouTube videos. Not only will it return the transcript, but it can also be used to translate those to translate those transcripts into other languages.  So now I can download my Ukrainian song, and see both the Ukrainian transcript and the English translation. This is pretty awesome!\n",
    "\n",
    "However, some videos do not contain transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube_transcript_api in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from youtube_transcript_api) (0.7.1)\n",
      "Requirement already satisfied: requests in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from youtube_transcript_api) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from requests->youtube_transcript_api) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from requests->youtube_transcript_api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from requests->youtube_transcript_api) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yingy/AI projects/youtube transcribe summary/youtube-and-video/.venv/lib/python3.12/site-packages (from requests->youtube_transcript_api) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --no-cache-dir youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Get all entries that are of type 'text' and NOT starting with [ \"\"\"\u001b[39;00m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([entry[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m transcript_data \n\u001b[32m     59\u001b[39m                                      \u001b[38;5;28;01mif\u001b[39;00m entry[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m] != \u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mget_transcripts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mget_transcripts\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_transcripts\u001b[39m():\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Extract existing transcript data from videos \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m \u001b[43murls\u001b[49m:\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;66;03m# Just so we can get the video title\u001b[39;00m\n\u001b[32m      9\u001b[39m             yt = YouTube(url, on_progress_callback=on_progress, client=\u001b[33m\"\u001b[39m\u001b[33mWEB\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'urls' is not defined"
     ]
    }
   ],
   "source": [
    "import youtube_transcript_api as yt_api\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "\n",
    "def get_transcripts():\n",
    "    \"\"\" Extract existing transcript data from videos \"\"\"\n",
    "    for url in urls:\n",
    "        try: # Just so we can get the video title\n",
    "            yt = YouTube(url, on_progress_callback=on_progress, client=\"WEB\")\n",
    "        except Exception as e:        \n",
    "            logger.error(f\"Error processing URL '{url}'.\")\n",
    "            logger.error(f\"The cause was: {e}\") \n",
    "            continue\n",
    "        \n",
    "        logger.info(f\"Processing '{yt.title}'...\")\n",
    "        video_id = get_video_id(url)\n",
    "        \n",
    "        try:\n",
    "            # By default, we get a list of 1: only get the preferred language transcript\n",
    "            transcript_list = yt_api.YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unable to extract transcript for '{yt.title}'.\")\n",
    "            logger.error(e)\n",
    "            continue\n",
    "        \n",
    "        # iterate over all available transcripts\n",
    "        for transcript in transcript_list:\n",
    "            # The Transcript object provides metadata properties. Here are some...\n",
    "            properties = {\n",
    "                \"video_id\": transcript.video_id,\n",
    "                \"language\": transcript.language,\n",
    "                \"language_code\": transcript.language_code,\n",
    "                \"is_generated\": transcript.is_generated,  # Whether it has been manually created or generated by YouTube\n",
    "                \"is_translatable\": transcript.is_translatable,  # Whether this transcript can be translated or not\n",
    "                \"translation_languages\": transcript.translation_languages,\n",
    "            }\n",
    "            \n",
    "            for prop, value in properties.items():\n",
    "                logger.info(f\"{prop}: {value}\")\n",
    "\n",
    "            # Fetch the actual transcript data\n",
    "            transcript_data = transcript.fetch() # returns a list of dicts\n",
    "            logger.info(f\"Raw transcript:\\n{transcript_data}\") \n",
    "            \n",
    "            processed_transcript = process_transcript(transcript_data)\n",
    "            logger.info(f\"Processed transcript:\\n{processed_transcript}\")\n",
    "            \n",
    "            # Translate to en if we can\n",
    "            if (transcript.language_code != \"en\" and \n",
    "                    transcript.is_translatable and \n",
    "                    any(lang['language_code'] == 'en' for lang in transcript.translation_languages)):\n",
    "                transcript_data = transcript.translate('en').fetch() # translate to en\n",
    "                processed_transcript = process_transcript(transcript_data)\n",
    "                logger.info(f\"Processed translated transcript:\\n{processed_transcript}\")\n",
    "\n",
    "def process_transcript(transcript_data):\n",
    "    \"\"\" Get all entries that are of type 'text' and NOT starting with [ \"\"\"\n",
    "    return \"\\n\".join([entry['text'] for entry in transcript_data \n",
    "                                     if entry['text'][0] != \"[\"])\n",
    "                \n",
    "get_transcripts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How cool is this!?\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In the next notebook, we'll look at adding Google Smarts, with some Google AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
